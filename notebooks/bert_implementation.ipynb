{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "BERT implementation\n",
    "\n",
    "You might want to add a CUDA device to the server\n",
    "\n",
    "https://www.infoworld.com/article/3299703/what-is-cuda-parallel-programming-for-gpus.html\n",
    "\n",
    "https://cloud.google.com/compute/docs/gpus/\n",
    "\n",
    "https://cloud.google.com/compute/docs/gpus/add-gpus\n",
    "\n",
    "https://cloud.google.com/products/calculator/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loads our wrapper classes\n",
    "\n",
    "we're not using NYTimes article feed\n",
    "instead of the News Title vs News Body, we have Question Title vs Question Body\n",
    "\n",
    "and we're going to make it based on Yuqing's framework, so it will be easier for Chi to adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Suggester_BertTopicSimiliarty():\n",
    "    def __init__(\n",
    "        self\n",
    "        , question_file\n",
    "        , answer_file\n",
    "        , sample_n\n",
    "        , random_state\n",
    "        , bert_cache\n",
    "        , logger\n",
    "        , device\n",
    "        , max_seq_length\n",
    "        , batch_size\n",
    "    ):\n",
    "        # initializes some vars\n",
    "        self.question_file = question_file\n",
    "        self.answer_file = answer_file\n",
    "        self.sample_n = sample_n\n",
    "        self.random_state = random_state\n",
    "        self.bert_cache = bert_cache\n",
    "        self.logger = logger\n",
    "        self.device = device\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # gets the pre-trained tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\"\n",
    "            , do_lower_case = True\n",
    "            , cache_dir = self.bert_cache\n",
    "        )\n",
    "        \n",
    "        # gets the pre-trained model\n",
    "        self.model = BertForNextSentencePrediction.from_pretrained(\n",
    "            \"bert-base-uncased\"\n",
    "            , cache_dir = self.bert_cache\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # instantiates the helper class\n",
    "        self.ceshiner = Ceshiner()\n",
    "    \n",
    "    \n",
    "    def _construct_corpus(self, questions, answers):\n",
    "        '''\n",
    "        helper function that constructs corpus\n",
    "        with question id, title, accepted answer id, answer body\n",
    "        note, implicitly only questions with accepted answers will end up in corpus\n",
    "        '''\n",
    "        t1 = questions[[\n",
    "            \"id\"\n",
    "            , \"title\"\n",
    "            , \"tags\"\n",
    "            , \"accepted_answer_id\"\n",
    "        ]].rename(columns = {\n",
    "            \"id\" : \"q_id\"\n",
    "            , \"title\" : \"q_title\"\n",
    "        })\n",
    "\n",
    "        t2 = answers[[\n",
    "            \"id\"\n",
    "            , \"body\"\n",
    "            , \"images_list\"\n",
    "            , \"code_snippets\"\n",
    "            , \"cleaned_body\"\n",
    "        ]].rename(columns = {\n",
    "            \"id\" : \"a_id\"\n",
    "            , \"body\" : \"a_body\"\n",
    "            , \"images_list\" : \"a_images_list\"\n",
    "            , \"code_snippets\" : \"a_code_snippets\"\n",
    "            , \"cleaned_body\" : \"a_cleaned_body\"\n",
    "        })\n",
    "\n",
    "        t3 = t1.merge(\n",
    "            t2\n",
    "            , left_on = \"accepted_answer_id\"\n",
    "            , right_on = \"a_id\"\n",
    "            , how = \"inner\"\n",
    "        ).drop(columns = \"a_id\")\n",
    "        \n",
    "        # ... removes any cleaned answers that are null\n",
    "        t4 = t3[t3.a_cleaned_body.notnull()]\n",
    "\n",
    "        if self.sample_n is not None:\n",
    "            t5 = t4.sample(self.sample_n, random_state = self.random_state)\n",
    "        else:\n",
    "            t5 = t4\n",
    "\n",
    "        return(t5)\n",
    "    \n",
    "    \n",
    "    def prepare(self):\n",
    "        '''\n",
    "        loads data & makes corpus\n",
    "        '''\n",
    "        self.questions = pd.read_csv(self.question_file, delimiter = \"\\t\", encoding = \"utf-8\")\n",
    "        self.answers = pd.read_csv(self.answer_file, delimiter = \"\\t\", encoding = \"utf-8\")\n",
    "        self.corpus = self._construct_corpus(self.questions, self.answers)\n",
    "        print(self.corpus.shape)\n",
    "    \n",
    "    def get_similar_documents(self, query, num_results = 5, threshold = 0.10):\n",
    "        sentence_pairs = self.ceshiner.convert_sentence_pair(\n",
    "            [query] * self.corpus.shape[0]\n",
    "            , self.corpus.a_cleaned_body.tolist()\n",
    "            , max_seq_length = self.max_seq_length\n",
    "            , tokenizer = self.tokenizer\n",
    "        )\n",
    "        similarity_scores = self.ceshiner.eval_pairs(\n",
    "            sentence_pairs = sentence_pairs\n",
    "            , batch_size = self.batch_size\n",
    "            , model = self.model\n",
    "        )\n",
    "        self.corpus_res = self.corpus.copy()\n",
    "        self.corpus_res[\"similarity\"] = similarity_scores\n",
    "        self.best_matches = self.corpus_res.copy()\n",
    "        self.best_matches = self.best_matches[self.best_matches['similarity'] >= threshold]\n",
    "        self.best_matches = self.best_matches.sort_values('similarity', ascending = False)\n",
    "        self.best_matches = self.best_matches[:num_results]\n",
    "#         res = np.argsort(self.similarity_scores)[::-1][:num_results]\n",
    "#         self.best_matches = self.corpus.iloc[res]\n",
    "        similar_que = self.best_matches[\"q_title\"]\n",
    "        similar_ans = self.best_matches[\"a_cleaned_body\"]\n",
    "        return(similar_que, similar_ans)\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, target):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.target = target\n",
    "        \n",
    "        \n",
    "class Ceshiner():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "                \n",
    "    def convert_sentence_pair(self, titles, descs, max_seq_length, tokenizer):\n",
    "        features = []\n",
    "        for (ex_index, (title, desc)) in enumerate(zip(titles, descs)):\n",
    "            tokens_a = tokenizer.tokenize(title)\n",
    "            \n",
    "            tokens_b = None\n",
    "            tokens_b = tokenizer.tokenize(desc)\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            self._truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "            # The convention in BERT is:\n",
    "            # (a) For sequence pairs:\n",
    "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "            #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "            # (b) For single sequences:\n",
    "            #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "            #  type_ids: 0   0   0   0  0     0 0\n",
    "            #\n",
    "            # Where \"type_ids\" are used to indicate whether this is the first\n",
    "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "            # embedding vector (and position vector). This is not *strictly* necessary\n",
    "            # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "            # it easier for the model to learn the concept of sequences.\n",
    "            #\n",
    "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "            # the entire model is fine-tuned.\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "            segment_ids = [0] * len(tokens)\n",
    "\n",
    "            if tokens_b:\n",
    "                tokens += tokens_b + [\"[SEP]\"]\n",
    "                segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding = [0] * (max_seq_length - len(input_ids))\n",
    "            input_ids += padding\n",
    "            input_mask += padding\n",
    "            segment_ids += padding\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            if ex_index < 5:\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"tokens: %s\" % \" \".join(\n",
    "                        [str(x) for x in tokens]))\n",
    "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                logger.info(\n",
    "                        \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "\n",
    "            features.append(\n",
    "                    InputFeatures(\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        target=1\n",
    "            ))\n",
    "        return features\n",
    "    \n",
    "    def eval_pairs(self, sentence_pairs, batch_size, model):\n",
    "        logger.info(\"***** Running evaluation *****\")\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in sentence_pairs], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in sentence_pairs], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in sentence_pairs], dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "        # Run prediction for full data\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler = eval_sampler, batch_size = batch_size)\n",
    "\n",
    "        logger.info(\"  Num examples = %d\", len(sentence_pairs))\n",
    "        logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        res = []\n",
    "\n",
    "        mb = progress_bar(eval_dataloader)\n",
    "        for input_ids, input_mask, segment_ids in mb:\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                res.append(nn.functional.softmax(\n",
    "                    model(input_ids, segment_ids, input_mask), dim=1\n",
    "                )[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        res = np.concatenate(res)\n",
    "        return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 09:52:27 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../models/bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "11/15/2019 09:52:28 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../models/bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/15/2019 09:52:28 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file ../models/bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpq894dvh5\n",
      "11/15/2019 09:52:32 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/15/2019 09:52:34 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "# i.e. app.py\n",
    "\n",
    "import gcsfs\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from pytorch_pretrained_bert.modeling import BertForNextSentencePrediction\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# defines seed for replication\n",
    "SEED = 20191114\n",
    "\n",
    "# defines cache folder for BERT model\n",
    "PYTORCH_PRETRAINED_BERT_CACHE = \"../models/bert/\"\n",
    "\n",
    "SAMPLE_SIZE = 10\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "# creates a logger\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(\"bert\")\n",
    "\n",
    "\n",
    "# detects the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# sets random states\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "# this uses gcsfs library\n",
    "# fs = gcsfs.GCSFileSystem(project='w210-jcgy-254100')\n",
    "# p_base_dir = \"w210-jcgy-bucket/w210-data-output-new-q-and-a-files-with-separate-cleaned-answer-bodies\"\n",
    "# p_questions = os.path.join(p_base_dir, \"PostQuestionsFiltered_V4_parsed.tsv\")\n",
    "# p_answers = os.path.join(p_base_dir, \"PostAnswersFiltered_V4_cleaned_answer_bodies.tsv\")\n",
    "# with fs.open(p_questions, 'rb') as f_q:\n",
    "#     with fs.open(p_answers, 'rb') as f_a:\n",
    "#         m = tfModel_BertTopicSimiliarty(f_q, f_a)\n",
    "\n",
    "# this relies on bucket being mounted, might be a bit faster to load the files\n",
    "p_base_dir = \"/mnt/disks/w210-jcgy-bucket/w210-data-output-new-q-and-a-files-with-separate-cleaned-answer-bodies\"\n",
    "p_questions = os.path.join(p_base_dir, \"PostQuestionsFiltered_V4_parsed.tsv\")\n",
    "p_answers = os.path.join(p_base_dir, \"PostAnswersFiltered_V4_cleaned_answer_bodies.tsv\")\n",
    "m = Suggester_BertTopicSimiliarty(\n",
    "    p_questions\n",
    "    , p_answers\n",
    "    , sample_n = SAMPLE_SIZE\n",
    "    , random_state = SEED\n",
    "    , bert_cache = PYTORCH_PRETRAINED_BERT_CACHE\n",
    "    , logger = logger\n",
    "    , device = device\n",
    "    , max_seq_length = MAX_SEQ_LENGTH\n",
    "    , batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "# loads data and builds a corpus\n",
    "m.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets similar queries\n",
    "similar_que, similar_ans = m.get_similar_documents(query = \"this is a query\", num_results = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = m.ceshiner.convert_sentence_pair(\n",
    "    titles = m.corpus.q_title.tolist()\n",
    "    , descs = m.corpus.a_cleaned_body.tolist()\n",
    "    , max_seq_length = 200\n",
    "    , tokenizer = m.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs_2 = m.ceshiner.convert_sentence_pair(\n",
    "    titles = [\"this is a query\"] * m.corpus.shape[0]\n",
    "    , descs = m.corpus.a_cleaned_body.tolist()\n",
    "    , max_seq_length = 200\n",
    "    , tokenizer = m.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123768       Invert image displayed by imshow in matplotlib\n",
      "47204     How to perform undirected graph processing fro...\n",
      "Name: q_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(similar_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123768     Specify the keyword argument or in your call ...\n",
      "47204      Ok, here's my stab at the problem. Here's a s...\n",
      "Name: a_cleaned_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(similar_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(m.corpus_res.similarity, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.0)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = m.corpus_res.similarity\n",
    "sum(t1 > 0.99) / len(t1), sum(t1 > 0.9) / len(t1), sum(t1 < 0.5) / len(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_title</th>\n",
       "      <th>tags</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>a_body</th>\n",
       "      <th>a_images_list</th>\n",
       "      <th>a_code_snippets</th>\n",
       "      <th>a_cleaned_body</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123768</th>\n",
       "      <td>8396101</td>\n",
       "      <td>Invert image displayed by imshow in matplotlib</td>\n",
       "      <td>pythonimagematplotlib</td>\n",
       "      <td>8396124.0</td>\n",
       "      <td>&lt;p&gt;Specify the keyword argument &lt;code&gt;origin='...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;code&gt;origin='lower'&lt;/code&gt;, &lt;code&gt;origin='up...</td>\n",
       "      <td>Specify the keyword argument or in your call ...</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47204</th>\n",
       "      <td>2807151</td>\n",
       "      <td>How to perform undirected graph processing fro...</td>\n",
       "      <td>sqlgraphactivemq</td>\n",
       "      <td>2807579.0</td>\n",
       "      <td>&lt;p&gt;Ok, here's my stab at the problem. &lt;/p&gt;\\r\\r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;code&gt;[nodes]\\r\\r\\nnode : varchar(xx)\\r\\r\\n\\r...</td>\n",
       "      <td>Ok, here's my stab at the problem. Here's a s...</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           q_id                                            q_title  \\\n",
       "123768  8396101     Invert image displayed by imshow in matplotlib   \n",
       "47204   2807151  How to perform undirected graph processing fro...   \n",
       "\n",
       "                         tags  accepted_answer_id  \\\n",
       "123768  pythonimagematplotlib           8396124.0   \n",
       "47204        sqlgraphactivemq           2807579.0   \n",
       "\n",
       "                                                   a_body a_images_list  \\\n",
       "123768  <p>Specify the keyword argument <code>origin='...            []   \n",
       "47204   <p>Ok, here's my stab at the problem. </p>\\r\\r...            []   \n",
       "\n",
       "                                          a_code_snippets  \\\n",
       "123768  [<code>origin='lower'</code>, <code>origin='up...   \n",
       "47204   [<code>[nodes]\\r\\r\\nnode : varchar(xx)\\r\\r\\n\\r...   \n",
       "\n",
       "                                           a_cleaned_body  similarity  \n",
       "123768   Specify the keyword argument or in your call ...    0.999989  \n",
       "47204    Ok, here's my stab at the problem. Here's a s...    0.999988  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_matches.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list of user input questions\n",
    "\n",
    "note, if running on just CPU, is way too slow even with only 600 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = [\n",
    "    'Is there a way to visualize the distribution of my data?'\n",
    "#     'How do I show data on a map?',\n",
    "#     'How can I illustrate changes in my data over time?',\n",
    "#     'Is there a way to show a “heatmap” of my data?',\n",
    "#     'How can I present a picture of a network?',\n",
    "#     'How can I plot a comparison of two data sets?',\n",
    "#     'How can I create a chart without coding?',\n",
    "#     'When should I use a bar chart versus a pie chart?',\n",
    "#     'What is the easiest way to create a diagram of a network?',\n",
    "#     'I need help creating a visualization/diagram/presentation of my data',\n",
    "#     'When should I use a scatter plot?',\n",
    "#     'Data visualization tips',\n",
    "#     'How do I make a network diagram in d3?',\n",
    "#     'How do I plot 2 datasets?',\n",
    "#     'How can I animate a bar chart in Python?',\n",
    "#     'I know how to create a line chart with matplotlib, but how do I do it in R?',\n",
    "#     'What is the easiest way to create a heat map of the US?',\n",
    "#     'How can I animate a choropleth in Tableau?  In PowerBI?  In D3?'\n",
    "]\n",
    "\n",
    "def g1(question_list, m):\n",
    "    res = []\n",
    "    res_df = pd.DataFrame()\n",
    "    for q in question_list:\n",
    "        similar_que, similar_ans = m.get_similar_documents(query = q, num_results = 5)\n",
    "        t1 = m.best_matches.copy()\n",
    "        t1[\"user_input\"] = q\n",
    "        t2 = t1[[\n",
    "            \"user_input\"\n",
    "            , \"similarity\"\n",
    "            , \"q_id\"\n",
    "            , \"q_title\"\n",
    "            , \"tags\"\n",
    "            , \"accepted_answer_id\"\n",
    "            , \"a_body\"\n",
    "            , \"a_cleaned_body\"\n",
    "        ]]\n",
    "        res.append(t2)\n",
    "    res_df = pd.concat(res)\n",
    "    res_df.sort_values([\"user_input\", \"similarity\"], ascending=[True, False])\n",
    "    return(res_df)\n",
    "\n",
    "t1 = g1(question_list,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>similarity</th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_title</th>\n",
       "      <th>tags</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>a_body</th>\n",
       "      <th>a_cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47204</th>\n",
       "      <td>Is there a way to visualize the distribution o...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>2807151</td>\n",
       "      <td>How to perform undirected graph processing fro...</td>\n",
       "      <td>sqlgraphactivemq</td>\n",
       "      <td>2807579.0</td>\n",
       "      <td>&lt;p&gt;Ok, here's my stab at the problem. &lt;/p&gt;\\r\\r...</td>\n",
       "      <td>Ok, here's my stab at the problem. Here's a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19203</th>\n",
       "      <td>Is there a way to visualize the distribution o...</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>53022319</td>\n",
       "      <td>How to get statistics from a histogram?</td>\n",
       "      <td>python-3.xnumpymatplotlib</td>\n",
       "      <td>53022701.0</td>\n",
       "      <td>&lt;p&gt;Based on my answer &lt;a href=\"https://stackov...</td>\n",
       "      <td>Based on my answer here skewness and kurtosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78853</th>\n",
       "      <td>Is there a way to visualize the distribution o...</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>19554822</td>\n",
       "      <td>Xcode command line tool - how to run in terminal?</td>\n",
       "      <td>xcodecommand-line</td>\n",
       "      <td>19554870.0</td>\n",
       "      <td>&lt;p&gt;Assuming your executable is named \"my_progr...</td>\n",
       "      <td>Assuming your executable is named \"my_program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141013</th>\n",
       "      <td>Is there a way to visualize the distribution o...</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>35909614</td>\n",
       "      <td>Plot Impulse Response Function (new)</td>\n",
       "      <td>rplot</td>\n",
       "      <td>35912971.0</td>\n",
       "      <td>&lt;p&gt;Assuming you have your &lt;code&gt;irf&lt;/code&gt; obj...</td>\n",
       "      <td>Assuming you have your object in you can firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176973</th>\n",
       "      <td>Is there a way to visualize the distribution o...</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>48912963</td>\n",
       "      <td>Powershell script running in vsts release not ...</td>\n",
       "      <td>powershellenvironment-variablesazure-devopsazu...</td>\n",
       "      <td>48913456.0</td>\n",
       "      <td>&lt;p&gt;Your problem is that you are using a &lt;em&gt;Bu...</td>\n",
       "      <td>Your problem is that you are using a Build va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               user_input  similarity  \\\n",
       "47204   Is there a way to visualize the distribution o...    0.999989   \n",
       "19203   Is there a way to visualize the distribution o...    0.999981   \n",
       "78853   Is there a way to visualize the distribution o...    0.999978   \n",
       "141013  Is there a way to visualize the distribution o...    0.999973   \n",
       "176973  Is there a way to visualize the distribution o...    0.999961   \n",
       "\n",
       "            q_id                                            q_title  \\\n",
       "47204    2807151  How to perform undirected graph processing fro...   \n",
       "19203   53022319            How to get statistics from a histogram?   \n",
       "78853   19554822  Xcode command line tool - how to run in terminal?   \n",
       "141013  35909614               Plot Impulse Response Function (new)   \n",
       "176973  48912963  Powershell script running in vsts release not ...   \n",
       "\n",
       "                                                     tags  accepted_answer_id  \\\n",
       "47204                                    sqlgraphactivemq           2807579.0   \n",
       "19203                           python-3.xnumpymatplotlib          53022701.0   \n",
       "78853                                   xcodecommand-line          19554870.0   \n",
       "141013                                              rplot          35912971.0   \n",
       "176973  powershellenvironment-variablesazure-devopsazu...          48913456.0   \n",
       "\n",
       "                                                   a_body  \\\n",
       "47204   <p>Ok, here's my stab at the problem. </p>\\r\\r...   \n",
       "19203   <p>Based on my answer <a href=\"https://stackov...   \n",
       "78853   <p>Assuming your executable is named \"my_progr...   \n",
       "141013  <p>Assuming you have your <code>irf</code> obj...   \n",
       "176973  <p>Your problem is that you are using a <em>Bu...   \n",
       "\n",
       "                                           a_cleaned_body  \n",
       "47204    Ok, here's my stab at the problem. Here's a s...  \n",
       "19203    Based on my answer here skewness and kurtosis...  \n",
       "78853    Assuming your executable is named \"my_program...  \n",
       "141013   Assuming you have your object in you can firs...  \n",
       "176973   Your problem is that you are using a Build va...  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
