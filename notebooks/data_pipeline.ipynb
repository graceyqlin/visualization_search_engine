{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "import dateutil.parser\n",
    "\n",
    "project_id = \"diesel-client-247517\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for Stack Overflow Question and Answers Posts Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of questions in Stack Overflow:         f0_\n",
      "0  18154493\n",
      "total number of answers in Stack Overflow:         f0_\n",
      "0  27665009\n"
     ]
    }
   ],
   "source": [
    "# how many total question and answer records are in Stack Overflow?\n",
    "sql = \"\"\"\n",
    "SELECT COUNT(*) FROM `bigquery-public-data.stackoverflow.posts_questions` \n",
    "\"\"\"\n",
    "\n",
    "numquestions = pandas_gbq.read_gbq(sql, project_id=project_id)\n",
    "print(\"total number of questions in Stack Overflow:\", numquestions)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT COUNT(*) FROM `bigquery-public-data.stackoverflow.posts_answers`\n",
    "\"\"\"\n",
    "\n",
    "numanswers = pandas_gbq.read_gbq(sql, project_id=project_id)\n",
    "print(\"total number of answers in Stack Overflow:\", numanswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code to extract the records from one table and load it into a pandas data frame\n",
    "# note that this can run a long time, depending on the number of records you are trying to load\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` WHERE (tags LIKE '%plot%' \n",
    "OR tags LIKE '%graph%'\n",
    "OR tags LIKE '%chart%'\n",
    "OR tags LIKE '%visualiz%'\n",
    "OR tags LIKE '%choropleth%'\n",
    "OR tags LIKE '%drawing%'\n",
    "OR tags LIKE '%line%'\n",
    "OR tags LIKE '%geospatial%'\n",
    "OR tags LIKE '%diagram%')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPostQuestionsFiltered = pandas_gbq.read_gbq(sql, project_id=project_id)\n",
    "\n",
    "dfPostQuestionsFiltered = dfPostQuestionsFiltered[dfPostQuestionsFiltered['answer_count'] >= 1]\n",
    "\n",
    "dfPostQuestionsFiltered['id'][dfPostQuestionsFiltered['accepted_answer_id'] == ''].count()\n",
    "\n",
    "dfPostQuestionsFiltered = dfPostQuestionsFiltered[dfPostQuestionsFiltered['accepted_answer_id'] != '']\n",
    "\n",
    "dfPostQuestionsFiltered['new_tags']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173698, 21)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfPostQuestionsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model tags file to be used to create the tag features from the tagtext field in the questions file, which\n",
    "# has all tag values concatenated without any separators\n",
    "\n",
    "\n",
    "dfModelTags = pd.read_csv(\"data/stackoverflow/modeltags_shortened.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find occurences of model tag values in tags filed, and append them to tbe new_tags field\n",
    "def parsetags(qtag):\n",
    "    tstr=''\n",
    "    for i in dfModelTags['tagtext']:\n",
    "        if i in qtag:\n",
    "            tstr=tstr + i + \" \"\n",
    "    return tstr\n",
    "\n",
    "dfPostQuestionsFiltered['new_tags'] = dfPostQuestionsFiltered['tags'].map(parsetags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a separate process to check for references to the r language in the question body\n",
    "# and set a separate 'r' column in the questions df to be used to update new_tags\n",
    "#\n",
    "# we cannot use the same process used on the tags above, since it will almost always find occurrences of 'r'\n",
    "# in the tags field that are just parts of other terms (for example, the \"r\" in \"chart\")\n",
    "#\n",
    "# So, here we look for standalone references to r in the question body instead\n",
    "#\n",
    "dfPostQuestionsFiltered['r'] = ''\n",
    "\n",
    "def testforr(x):\n",
    "    if (' r ' in x) or (' r,' in x) or (' r.' in x) or (' r:' in x):\n",
    "        return 'r '\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "dfPostQuestionsFiltered['r'] = dfPostQuestionsFiltered['body'].map(testforr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, update new_tags, appending the 'r' for questions referencing r in the question body\n",
    "dfPostQuestionsFiltered['new_tags'] = dfPostQuestionsFiltered['new_tags'] + dfPostQuestionsFiltered['r']\n",
    "\n",
    "dfPostQuestionsFiltered['new_tags'][dfPostQuestionsFiltered['r']=='r ']\n",
    "\n",
    "dfPostQuestionsFiltered['id'][dfPostQuestionsFiltered['new_tags'] == ''].count()\n",
    "\n",
    "dfPostQuestionsFiltered = dfPostQuestionsFiltered[dfPostQuestionsFiltered['new_tags'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278533, 21)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfPostQuestionsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now create a separate question body column, 'cleaned_question_body', that removes all the code and all HTL tags\n",
    "# from the question body\n",
    "# We might use the cleaned_question_body as a feature in one of the similarity models\n",
    "def clean_ques_body_text(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    for code in tmp_body('code'):\n",
    "        code.replace_with('')\n",
    "    tstr=''\n",
    "    for string in tmp_body.stripped_strings:\n",
    "        tstr = tstr + ' ' + string\n",
    "    return tstr\n",
    "\n",
    "dfPostQuestionsFiltered['cleaned_question_body']=''\n",
    "\n",
    "sttime=time.time()   \n",
    " \n",
    "dfPostQuestionsFiltered['cleaned_question_body'] = dfPostQuestionsFiltered['body'].map(clean_ques_body_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <p>I have configured and set up a fully functi...\n",
       "6     <p>I want to use a mutation in an event handle...\n",
       "10    <p>I have useQuery and useMutation from react-...\n",
       "70    <p>I'm coding in R and I have the following da...\n",
       "72    <p>I am graphing the internet connection in my...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPostQuestionsFiltered['body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      I have configured and set up a fully function...\n",
       "6      I want to use a mutation in an event handler....\n",
       "10     I have useQuery and useMutation from react-ap...\n",
       "70     I'm coding in R and I have the following data...\n",
       "72     I am graphing the internet connection in my a...\n",
       "Name: cleaned_question_body, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPostQuestionsFiltered['cleaned_question_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write the dataframe to a csv\n",
    "dfPostQuestionsFiltered.to_csv(\"data/stackoverflow/PostQuestionsFiltered_V5_parsed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the answers that belong to the questions retrieved above\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * FROM `bigquery-public-data.stackoverflow.posts_answers` WHERE parent_id IN \n",
    "    (SELECT id FROM `bigquery-public-data.stackoverflow.posts_questions` WHERE (tags LIKE '%plot%' \n",
    "        OR tags LIKE '%graph%'\n",
    "        OR tags LIKE '%chart%'\n",
    "        OR tags LIKE '%visualiz%'\n",
    "        OR tags LIKE '%choropleth%'\n",
    "        OR tags LIKE '%drawing%'\n",
    "        OR tags LIKE '%line%'\n",
    "        OR tags LIKE '%geospatial%'\n",
    "        OR tags LIKE '%diagram%'))\n",
    "\"\"\"\n",
    "dfPostAnswersFiltered = pandas_gbq.read_gbq(sql, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545457, 20)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfPostAnswersFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to a tsv\n",
    "dfPostAnswersFiltered.to_csv(\"data/stackoverflow/PostAnswersFiltered_raw_12_06_19.tsv\", sep='\\t', index=False)\n",
    "\n",
    "# let's drop any answers that do not have corresponding questions in our questions dataframe\n",
    "tmpid=pd.DataFrame(dfPostQuestionsFiltered['id']) # temporary dataframe to hold ids from questions for merge operation\n",
    "tmpid.columns=['tempqid']\n",
    "dfPostAnswersFiltered=pd.merge(dfPostAnswersFiltered, tmpid, how='inner',left_on='parent_id',right_on='tempqid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261052, 21)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfPostAnswersFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images finished in 4.315905344486237 minutes\n"
     ]
    }
   ],
   "source": [
    "# check the answer body of each answer and extract the images references into a separate column as a list\n",
    "def extract_image_references(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    timgs=[]\n",
    "    for img in tmp_body('img'):\n",
    "        timgs.append(img)\n",
    "    return timgs\n",
    "\n",
    "sttime=time.time()    \n",
    "\n",
    "dfPostAnswersFiltered['images_list']=''\n",
    "\n",
    "dfPostAnswersFiltered['images_list'] = dfPostAnswersFiltered['body'].map(extract_image_references)\n",
    "print('images finished in',(time.time()-sttime)/60,'minutes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code snippets finished in 4.729599332809448 minutes\n"
     ]
    }
   ],
   "source": [
    "# check the answer body of each answer and extract the code snippets into a separate column as a list\n",
    "def extract_code_snippets(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    tcode_snips=[]\n",
    "    for code in tmp_body('code'):\n",
    "        tcode_snips.append(code)\n",
    "    return tcode_snips\n",
    "\n",
    "sttime=time.time()    \n",
    "\n",
    "dfPostAnswersFiltered['code_snippets']=''\n",
    "\n",
    "dfPostAnswersFiltered['code_snippets'] = dfPostAnswersFiltered['body'].map(extract_code_snippets)\n",
    "print('code snippets finished in',(time.time()-sttime)/60,'minutes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body cleaned in 4.306883104642233 minutes\n"
     ]
    }
   ],
   "source": [
    "# create a separate 'cleaned_body' column from the answer 'body' column with all code and all html tags removed\n",
    "def clean_body_text(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    for code in tmp_body('code'):\n",
    "        code.replace_with('')\n",
    "    tstr=''\n",
    "    for string in tmp_body.stripped_strings:\n",
    "        tstr = tstr + ' ' + string\n",
    "    return tstr\n",
    "\n",
    "dfPostAnswersFiltered['cleaned_body']=''\n",
    "\n",
    "sttime=time.time()    \n",
    "dfPostAnswersFiltered['cleaned_body'] = dfPostAnswersFiltered['body'].map(clean_body_text)\n",
    "print('body cleaned in',(time.time()-sttime)/60,'minutes')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <p>The correct syntax is this one:</p>\\r\\n\\r\\n...\n",
       "1    <p>You can download the plugin manually from t...\n",
       "2    <p>You can define the lines from the dataset w...\n",
       "3    <p>The way matplotlib is working is that you h...\n",
       "4    <p>I have figured out the answer, which is to ...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPostAnswersFiltered['body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     The correct syntax is this one: It is working...\n",
       "1     You can download the plugin manually from the...\n",
       "2     You can define the lines from the dataset wit...\n",
       "3     The way matplotlib is working is that you hav...\n",
       "4     I have figured out the answer, which is to us...\n",
       "Name: cleaned_body, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPostAnswersFiltered['cleaned_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [<code>plugin install com.graphaware.es/graph-...\n",
       "1                                                   []\n",
       "2           [<code>mapping.get(i, \"anchor\"),\n",
       "</code>]\n",
       "3    [<code>def error_plot(ax, title, x_data, y_dat...\n",
       "4    [<code>%sql select t1.time, t1.value,coalesce(...\n",
       "Name: code_snippets, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPostAnswersFiltered['code_snippets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an image count column to the answers so that we can filter on answers with images\n",
    "def countimages(image_list):\n",
    "    if image_list == []:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(image_list)\n",
    "    \n",
    "dfPostAnswersFiltered['images_count']=0\n",
    "dfPostAnswersFiltered['images_count'] = dfPostAnswersFiltered['images_list'].map(countimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to a tsv\n",
    "dfPostAnswersFiltered.to_csv(\"data/stackoverflow/PostAnswersFiltered_V5_parsed.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving user ids for owners of the answers retrieved above\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * FROM `bigquery-public-data.stackoverflow.users` WHERE id IN\n",
    "    (SELECT owner_user_id FROM `bigquery-public-data.stackoverflow.posts_answers` WHERE parent_id IN \n",
    "        (SELECT id FROM `bigquery-public-data.stackoverflow.posts_questions` WHERE (tags LIKE '%plot%' \n",
    "            OR tags LIKE '%graph%'\n",
    "            OR tags LIKE '%chart%'\n",
    "            OR tags LIKE '%visualiz%'\n",
    "            OR tags LIKE '%choropleth%'\n",
    "            OR tags LIKE '%drawing%'\n",
    "            OR tags LIKE '%line%'\n",
    "            OR tags LIKE '%geospatial%'\n",
    "            OR tags LIKE '%diagram%')))\n",
    "\"\"\"\n",
    "dfUsersFiltered = pandas_gbq.read_gbq(sql, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304366, 13)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfUsersFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write the dataframe to a tsv\n",
    "dfUsersFiltered.to_csv(\"data/stackoverflow/UsersFiltered_V3.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the comments that belong to the questions retrieved above\n",
    "\n",
    "# NOTE - the below select may only retrieve comments related to questions??\n",
    "\n",
    "# is a separate select needed to retrieve comments related to the answers?\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * FROM `bigquery-public-data.stackoverflow.comments` WHERE post_id IN \n",
    "    (SELECT id FROM `bigquery-public-data.stackoverflow.posts_questions` WHERE (tags LIKE '%plot%' \n",
    "        OR tags LIKE '%graph%'\n",
    "        OR tags LIKE '%chart%'\n",
    "        OR tags LIKE '%visualiz%'\n",
    "        OR tags LIKE '%choropleth%'\n",
    "        OR tags LIKE '%drawing%'\n",
    "        OR tags LIKE '%line%'\n",
    "        OR tags LIKE '%geospatial%'\n",
    "        OR tags LIKE '%diagram%'))\n",
    "\"\"\"\n",
    "dfCommentsFiltered = pandas_gbq.read_gbq(sql, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184056, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfCommentsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to a tsv\n",
    "dfCommentsFiltered.to_csv(\"data/stackoverflow/CommentsFiltered_v3.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for Stack Exchange Data Science Community Question and Answers Posts Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to load raw Data Science Stack Exchange questions and answers to Pandas dfs -- Note that you may have to change the path to the .tsv \n",
    "# file in the statement below depending on the location you downladed the .tsv to\n",
    "\n",
    "dfDSPosts = pd.read_csv(\"Data/Stack Exchange Data Science/Posts_From_Data_Science_Stack_Exchange.csv\", keep_default_na=False)\n",
    "\n",
    "dfDSQues=dfDSPosts[dfDSPosts['PostTypeId']==1]\n",
    "dfDSAns=dfDSPosts[dfDSPosts['PostTypeId']==2]\n",
    "\n",
    "del dfDSPosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20502, 22)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSQues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22666, 22)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfDSQues['AnswerCount'][dfDSQues['AnswerCount'] != '0'].count()\n",
    "\n",
    "dfDSQues = dfDSQues[dfDSQues['AnswerCount'] != '0' ]\n",
    "\n",
    "dfDSQues = dfDSQues[dfDSQues['AcceptedAnswerId'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6694, 22)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSQues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model tags file to be used to create the tag features from the tagtext field in the questions file, which\n",
    "# has all tag values concatenated without any separators\n",
    "\n",
    "# NOTE: Used shortened version of model tag list below\n",
    "\n",
    "dfModelTags = pd.read_csv(\"data/stackoverflow/modeltags_shortened.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find occurences of model tag values in tags filed, and append them to tbe new_tags field\n",
    "def parsetags(qtag):\n",
    "    tstr=''\n",
    "    for i in dfModelTags['tagtext']:\n",
    "        if i in qtag:\n",
    "            tstr=tstr + i + \" \"\n",
    "    return tstr\n",
    "\n",
    "dfDSQues['new_tags'] = dfDSQues['Tags'].map(parsetags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a separate process to check for references to the r language in the question body\n",
    "# and set a separate 'r' column in the questions df to be used to update new_tags\n",
    "#\n",
    "# we cannot use the same process used on the tags above, since it will almost always find occurrences of 'r'\n",
    "# in the tags field that are just parts of other terms (for example, the \"r\" in \"chart\")\n",
    "#\n",
    "# So, here we look for standalone references to r in the question body instead\n",
    "#\n",
    "dfDSQues['r'] = ''\n",
    "\n",
    "def testforr(x):\n",
    "    if (' r ' in x) or (' r,' in x) or (' r.' in x) or (' r:' in x):\n",
    "        return 'r '\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "dfDSQues['r'] = dfDSQues['Body'].map(testforr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5109"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, update new_tags, appending the 'r' for questions referencing r in the question body\n",
    "dfDSQues['new_tags'] = dfDSQues['new_tags'] + dfDSQues['r']\n",
    "\n",
    "# now, let's drop any questions that do not have tags we are interested in\n",
    "\n",
    "dfDSQues['Id'][dfDSQues['new_tags'] == ''].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDSQues = dfDSQues[dfDSQues['new_tags'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1585, 23)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSQues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now create a separate question body column, 'cleaned_question_body', that removes all the code and all HTL tags\n",
    "# from the question body\n",
    "# We might use the cleaned_question_body as a feature in one of the similarity models\n",
    "def clean_ques_body_text(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    for code in tmp_body('code'):\n",
    "        code.replace_with('')\n",
    "    tstr=''\n",
    "    for string in tmp_body.stripped_strings:\n",
    "        tstr = tstr + ' ' + string\n",
    "    return tstr\n",
    "\n",
    "dfDSQues['cleaned_question_body']=''\n",
    "\n",
    "sttime=time.time()    \n",
    "dfDSQues['cleaned_question_body'] = dfDSQues['Body'].map(clean_ques_body_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53    <p>I have a excel data with time stamp format ...\n",
       "56    <p>I am learning <a href=\"https://en.wikipedia...\n",
       "65    <p>I have trained an ANN model for a regressio...\n",
       "84    <p>I'm getting confused as how to proceed for ...\n",
       "90    <p>I am learning <a href=\"https://en.wikipedia...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDSQues['Body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53     I have a excel data with time stamp format li...\n",
       "56     I am learning SVD by following this MIT cours...\n",
       "65     I have trained an ANN model for a regression ...\n",
       "84     I'm getting confused as how to proceed for th...\n",
       "90     I am learning SVD by following this MIT cours...\n",
       "Name: cleaned_question_body, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDSQues['cleaned_question_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write the dataframe to a tsv\n",
    "dfDSQues.to_csv(\"data/stackoverflow/DataSciQues_parsed.tsv\", sep='\\t', index=False)\n",
    "\n",
    "# write the dataframe to a csv\n",
    "dfDSQues.to_csv(\"data/stackoverflow/DataSciQues_parsed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's drop any answers that do not have corresponding questions in our questions dataframe\n",
    "tmpid=pd.DataFrame(dfDSQues['Id']) # temporary dataframe to hold ids from questions for merge operation\n",
    "tmpid.columns=['tempqid']\n",
    "dfDSAns=pd.merge(dfDSAns, tmpid, how='inner',left_on=pd.to_numeric(dfDSAns['ParentId'], downcast='integer'),right_on='tempqid')\n",
    "del dfDSAns['tempqid']\n",
    "del tmpid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2410, 22)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images finished in 0.018283510208129884 minutes\n"
     ]
    }
   ],
   "source": [
    "# check the answer body of each answer and extract the images references into a separate column as a list\n",
    "def extract_image_references(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    timgs=[]\n",
    "    for img in tmp_body('img'):\n",
    "        timgs.append(img)\n",
    "    return timgs\n",
    "\n",
    "sttime=time.time()    \n",
    "\n",
    "dfDSAns['images_list']=''\n",
    "\n",
    "dfDSAns['images_list'] = dfDSAns['Body'].map(extract_image_references)\n",
    "print('images finished in',(time.time()-sttime)/60,'minutes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code snippets finished in 0.0185501495997111 minutes\n"
     ]
    }
   ],
   "source": [
    "# check the answer body of each answer and extract the code snippets into a separate column as a list\n",
    "def extract_code_snippets(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    tcode_snips=[]\n",
    "    for code in tmp_body('code'):\n",
    "        tcode_snips.append(code)\n",
    "    return tcode_snips\n",
    "\n",
    "sttime=time.time()    \n",
    "\n",
    "dfDSAns['code_snippets']=''\n",
    "\n",
    "dfDSAns['code_snippets'] = dfDSAns['Body'].map(extract_code_snippets)\n",
    "print('code snippets finished in',(time.time()-sttime)/60,'minutes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body cleaned in 0.01733266512552897 minutes\n"
     ]
    }
   ],
   "source": [
    "# create a separate 'cleaned_body' column from the answer 'body' column with all code and all html tags removed\n",
    "def clean_body_text(body):\n",
    "    tmp_body=BeautifulSoup(body,\"lxml\")\n",
    "    for code in tmp_body('code'):\n",
    "        code.replace_with('')\n",
    "    tstr=''\n",
    "    for string in tmp_body.stripped_strings:\n",
    "        tstr = tstr + ' ' + string\n",
    "    return tstr\n",
    "\n",
    "dfDSAns['cleaned_body']=''\n",
    "\n",
    "sttime=time.time()    \n",
    "dfDSAns['cleaned_body'] = dfDSAns['Body'].map(clean_body_text)\n",
    "print('body cleaned in',(time.time()-sttime)/60,'minutes')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <p>As We should not remove any data ... we can...\n",
       "1    <p>Consider using the <a href=\"https://en.wiki...\n",
       "2    <p>You could take an <a href=\"https://en.wikip...\n",
       "3    <p>Did you try keeping a separate test set (on...\n",
       "4    <p>From the curves you are showing <strong>yes...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDSAns['Body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     As We should not remove any data ... we can u...\n",
       "1     Consider using the Earth Mover's Distance (i....\n",
       "2     You could take an Information Theory approach...\n",
       "3     Did you try keeping a separate test set (on t...\n",
       "4     From the curves you are showing yes . Over-fi...\n",
       "Name: cleaned_body, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDSAns['cleaned_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an image count column to the answers so that we can filter on answers with images\n",
    "def countimages(image_list):\n",
    "    if image_list == []:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(image_list)\n",
    "    \n",
    "dfDSAns['images_count']=0\n",
    "dfDSAns['images_count'] = dfDSAns['images_list'].map(countimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to a tsv\n",
    "dfDSAns.to_csv(\"data/stackoverflow/DataSciAns_parsed.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CODE TO LOAD THE DATA SCIENCE ANSWERS TO A PANDAS DATAFRAME -- Note that you may have to change the path to the .tsv \n",
    "# file in the statement below depending on the location you downladed the .tsv to\n",
    "dfDSAns = pd.read_csv(\"data/stackoverflow/DataSciAns_parsed.tsv\", sep='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check to see if there duplicate ids in the Stack Overflow and Data Science Stack Exchange datasets before\n",
    "# combining them\n",
    "tsoquesids=pd.DataFrame(dfPostQuestionsFiltered['id'])\n",
    "tsoansids=pd.DataFrame(dfPostAnswersFiltered['id'])\n",
    "tdsquesids=pd.DataFrame(dfDSQues['Id'])\n",
    "tdsansids=pd.DataFrame(dfDSAns['Id'])\n",
    "tmergeques=pd.merge(tsoquesids, tdsquesids, how='inner', left_on='id', right_on='Id')\n",
    "tmergeans=pd.merge(tsoansids, tdsansids, how='inner', left_on='id', right_on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate question Ids to be dropped: [58649]\n"
     ]
    }
   ],
   "source": [
    "# dropping questions with duplicate ids from the Stack Overflow and data science question sets\n",
    "# also dropping answers that refer back to those duplicate questions\n",
    "# note: we do not drop answers that happen to have duplicate ids as the risk of getting bad return results\n",
    "# in our models is minimal for duplicate answers, espcially given the small number of duplicate answer ids\n",
    "qidstodrop=tmergeques['Id'].values.tolist()\n",
    "print('duplicate question Ids to be dropped:',qidstodrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 7 answers from SO answers that have question parent id = 58649\n",
      "dropping 1 answers from DS answers that have question parent id = 58649\n",
      "dropping quesion from SO that has question = 58649\n",
      "dropping quesion from DS that has question = 58649\n"
     ]
    }
   ],
   "source": [
    "for dupqid in qidstodrop:\n",
    "    \n",
    "    SOanswithdupqids=dfPostAnswersFiltered['id'][dfPostAnswersFiltered['parent_id']==dupqid].index\n",
    "    print('dropping',len(SOanswithdupqids),'answers from SO answers that have question parent id =',dupqid)\n",
    "    dfPostAnswersFiltered.drop(labels=SOanswithdupqids,inplace=True)\n",
    "    \n",
    "    DSanswithdupqids=dfDSAns['Id'][dfDSAns['ParentId']==dupqid].index\n",
    "    print('dropping',len(DSanswithdupqids),'answers from DS answers that have question parent id =',dupqid)\n",
    "    dfDSAns.drop(labels=DSanswithdupqids,inplace=True)\n",
    "\n",
    "    print('dropping quesion from SO that has question =',dupqid)\n",
    "    dfPostQuestionsFiltered.drop(labels=dfPostQuestionsFiltered[dfPostQuestionsFiltered['id']==dupqid].index,inplace=True)\n",
    "\n",
    "    print('dropping quesion from DS that has question =',dupqid)\n",
    "    dfDSQues.drop(labels=dfDSQues[dfDSQues['Id']==dupqid].index,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataframes after dropping duplicate question Ids -- SO ques: 173697 DS ques 1584 SO ans: 261045 DS ans 2409\n"
     ]
    }
   ],
   "source": [
    "print('length of dataframes after dropping duplicate question Ids -- SO ques:',len(dfPostQuestionsFiltered), 'DS ques', len(dfDSQues),'SO ans:',len(dfPostAnswersFiltered), 'DS ans', len(dfDSAns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'body', 'accepted_answer_id', 'answer_count',\n",
       "       'comment_count', 'community_owned_date', 'creation_date',\n",
       "       'favorite_count', 'last_activity_date', 'last_edit_date',\n",
       "       'last_editor_display_name', 'last_editor_user_id', 'owner_display_name',\n",
       "       'owner_user_id', 'parent_id', 'post_type_id', 'score', 'tags',\n",
       "       'view_count', 'images_list', 'code_snippets', 'cleaned_body',\n",
       "       'images_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPostAnswersFiltered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column names in data science answers dataset to match those in the Stack Overflow answers dataset\n",
    "dfDSAns.columns = ['id', 'post_type_id', 'accepted_answer_id', 'parent_id', 'creation_date', 'score', \n",
    "                   'view_count', 'body', 'owner_user_id', 'owner_display_name', 'last_editor_user_id', \n",
    "                   'last_editor_display_name', 'last_edit_date', 'last_activity_date', 'title', 'tags',\n",
    "                   'answer_count', 'comment_count', 'favorite_count', 'community_owned_date', \n",
    "                   'images_list', 'code_snippets', 'cleaned_body', 'images_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedAns=dfPostAnswersFiltered.append(dfDSAns,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261045, 24)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfPostAnswersFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2409, 24)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263454, 24)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfCombinedAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column names in data science answers dataset to match those in the Stack Overflow answers dataset\n",
    "dfDSQues.columns = ['id', 'post_type_id', 'accepted_answer_id', 'parent_id', 'creation_date', 'score', \n",
    "                   'view_count', 'body', 'owner_user_id', 'owner_display_name', 'last_editor_user_id', \n",
    "                   'last_editor_display_name', 'last_edit_date', 'last_activity_date', 'title', 'tags',\n",
    "                   'answer_count', 'comment_count', 'favorite_count', 'community_owned_date', \n",
    "                   'new_tags', 'cleaned_question_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombinedQues=dfPostQuestionsFiltered.append(dfDSQues,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173697, 22)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfPostQuestionsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584, 22)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfDSQues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175281, 22)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dfCombinedQues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the combined questions dataframe to a tsv\n",
    "dfCombinedQues.to_csv(\"data/stackoverflow/SODSQues_parsed.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the combined questions dataframe to a csv\n",
    "dfCombinedQues.to_csv(\"data/stackoverflow/SODSQues_parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CODE TO LOAD THE SO + DATA SCIENCE QUESTIONS TO A PANDAS DATAFRAME -- Note that you may have to change the path to the .tsv \n",
    "# file in the statement below depending on the location you downladed the .tsv to\n",
    "dfCombinedQues = pd.read_csv(\"data/stackoverflow/SODSQues_parsed.tsv\", sep='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the combined answers dataframe to a tsv\n",
    "dfCombinedAns.to_csv(\"data/stackoverflow/SODSAns_parsed.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CODE TO LOAD THE SO + DATA SCIENCE ANSWERS TO A PANDAS DATAFRAME -- Note that you may have to change the path to the .tsv \n",
    "# file in the statement below depending on the location you downladed the .tsv to\n",
    "dfCombinedAns = pd.read_csv(\"data/stackoverflow/SODSAns_parsed.tsv\", sep='\\t', keep_default_na=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
